{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17709bf3-8026-4fe7-8e5e-9325257f6da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pysetup/.venv/lib/python3.11/site-packages/chime_frb_api/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution as _get_distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from iautils import cascade\n",
    "\n",
    "from datetime import datetime\n",
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16662ef-d261-447b-a8e1-166a0d1a614a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/arc/home/mseth/.local/lib/python3.11/site-packages\")\n",
    "import memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aeee4be-cf64-40f9-b44d-7518d551161d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e99e02-87bd-41ea-ab4d-3fc166a1adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('beam-model'))\n",
    "from beam_model import utils, formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ff484-e255-46b1-9255-0ce3fce8d971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b8bc6-c083-49d2-b32d-9927f74fdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.linspace(400.390625, 800, 256)            # The data has 256 frequency channels\n",
    "has = np.array(np.linspace(-105, 104.90278, 1024))   # 1024 HAs\n",
    "\n",
    "source_name = \"CYG_A\"\n",
    "coords = SkyCoord.from_name(source_name)\n",
    "source_ra = coords.ra.deg\n",
    "source_dec = coords.dec.deg\n",
    "\n",
    "\n",
    "# BF to JY conversion equation\n",
    "def bf_to_jy(bf_spectrum, f_good):\n",
    "    factor = (np.square(1024) * 128) / (np.square(4) * 0.806745 * 400)\n",
    "    result = bf_spectrum / ( factor * np.square(f_good) ) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51606cbc-7a30-4747-84d5-96e5f8d05bfb",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35c19e-825b-417b-9c22-46d3f0bd5abe",
   "metadata": {},
   "source": [
    "Stuff we define beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7fae250-c5f1-4c8d-b712-8a9d889265a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "dms = []\n",
    "cascade_objs = []\n",
    "path = \"/arc/projects/chime_frb/mseth/tau_A_data/initial_try\"\n",
    "\n",
    "for (root, dirs, file) in os.walk(path):\n",
    "    for f in file: \n",
    "        filepaths.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df379a7-2068-49e2-9310-26d610d14a39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n",
      "De-dispersing to 57.7 pc cm-3..\n",
      "Using 400.1953125 MHz as reference..\n",
      "Padding shifted channels using median value..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "dms = []\n",
    "max_tidxs = []\n",
    "max_timestamps = []\n",
    "\n",
    "for filepath in filepaths:\n",
    "    try:\n",
    "        cascade_obj = cascade.load_cascade_from_file(filepath)\n",
    "        cascade_obj.dm=57.70 \n",
    "        dm = cascade_obj.best_snr_dm\n",
    "        \n",
    "        if dm >= 55 or dm <= 57:\n",
    "            ts = np.nansum(cascade_obj.beams[cascade_obj._max_beam_idx].intensity, axis=0)\n",
    "            max_tidx = np.argmax(ts)\n",
    "            max_timestamp = cascade_obj.event_time + pd.Timedelta(seconds = max_tidx / 1000)\n",
    "\n",
    "            max_tidxs.append(max_tidx)\n",
    "            max_timestamps.append(max_timestamp)\n",
    "            dms.append(dm)\n",
    "            del cascade_obj\n",
    "        else:\n",
    "            del cascade_obj\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15dc68-9b42-4906-b9c0-45e3310351ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pysetup/.venv/lib/python3.11/site-packages/chime_frb_api/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution as _get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n",
      "Preprocessing...\n",
      "using L1 weights\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "from iautils import cascade\n",
    "\n",
    "path = \"/arc/projects/chime_frb/mseth/tau_A_data/initial_try\"\n",
    "\n",
    "filepaths = []\n",
    "dms = []\n",
    "cascade_objs = []\n",
    "\n",
    "for (root, dirs, file) in os.walk(path):\n",
    "    for f in file: \n",
    "        filepaths.append(os.path.join(root, f))\n",
    "        \n",
    "for filepath in filepaths:\n",
    "        # Load the cascade file\n",
    "    try:\n",
    "        cascade_obj = cascade.load_cascade_from_file(filepath)\n",
    "        #cascade_obj.dm=57.70 ## De-dispersing at 57.70\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    #dm = cascade_obj.best_snr_dm\n",
    "    #dms.append(dm)\n",
    "    cascade_objs.append(cascade_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504c891-07e6-4300-a662-40fce0822558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f4a31-b540-439b-8427-b7bc0d067866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/arc/projects/chime_frb/mseth/tau_A_data\"\n",
    "\n",
    "filepaths = []\n",
    "dms = []\n",
    "cascade_objs = []\n",
    "\n",
    "for (root, dirs, file) in os.walk(path):\n",
    "    for f in file: \n",
    "        filepaths.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe4b6d-760e-42ce-b4dc-233021106441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA ## \n",
    "max_tidxs = []             # Time index at peak\n",
    "max_timestamps = []        # Timestamp of peak\n",
    "spectra_at_peak = []       # Spectrum at peak time\n",
    "beam_ids = []              # Beam ID that detected peak\n",
    "has_at_peak = []           # HA of peak detection\n",
    "\n",
    "for i, cascade_obj in enumerate(cascade_objs):\n",
    "    ts = np.nansum(cascade_objs[i].beams[cascade_objs[i]._max_beam_idx].intensity, axis=0)\n",
    "    \n",
    "    max_tidx = np.argmax(ts)\n",
    "    max_timestamp = cascade_objs[i].event_time + pd.Timedelta(seconds = max_tidx / 1000)\n",
    "    spectrum_at_peak = cascade_objs[i].beams[cascade_objs[i]._max_beam_idx].intensity[:, max_tidx]\n",
    "    beam_id = cascade_obj.beams[cascade_obj.__max_beam_id].beam_no\n",
    "\n",
    "    x, y = utils.get_position_from_equatorial(source_ra, source_dec, max_timestamp)\n",
    "    \n",
    "    max_tidxs.append(max_tidx)\n",
    "    max_timestamps.append(max_timestamp)\n",
    "    spectra_at_peak.append(spectrum_at_peak)\n",
    "    has_at_peak.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c77ad-e293-4f15-96d5-0a2d554d7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(freqs, spectra_at_peak[0])\n",
    "plt.title(\"Example of uncorrected data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6b055-f41d-4fd7-940d-2210909aefc7",
   "metadata": {},
   "source": [
    "Beams & Correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f333e-02eb-4aac-85a1-55df19832202",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRIMARY BEAM RESPONSE ##\n",
    "\n",
    "# Load in holography data \n",
    "path = \"/users/mseth/holography_data/npz_files\"\n",
    "\n",
    "npz_files = []\n",
    "for (root, dirs, file) in os.walk(path):\n",
    "    for f in file: \n",
    "        npz_files.append(os.path.join(root, f))\n",
    "xx_list = []\n",
    "yy_list = []\n",
    "for file in npz_files:\n",
    "    data = np.load(file)\n",
    "    xx = data['XX']\n",
    "    yy = data['YY']\n",
    "    xx_list.append(xx)\n",
    "    yy_list.append(yy)\n",
    "\n",
    "xx = np.vstack(xx_list)\n",
    "yy = np.vstack(yy_list)\n",
    "intensity = xx + yy / 2\n",
    "\n",
    "# Get spectra at every peak HA \n",
    "presponse_norm = []\n",
    "\n",
    "for ha in has_at_peak:\n",
    "    idx = (np.abs(has - ha)).argmin()         # Find index of closest HA to HA at peak\n",
    "    xx_response = xx[:,idx]\n",
    "    yy_response = yy[:, idx]\n",
    "    \n",
    "    int_response = intensity[:,idx]           # Get intensity spectrum at that HA \n",
    "    int_masked = intensity[:,1760:1840]       # Get maximum intensity in the main beam\n",
    "    inty_max = np.max(intensity_masked)       \n",
    "    \n",
    "    int_norm = int_response / intensity_max   # Normalize intensity spectrum at the HA\n",
    "    presponse_norm.append(int_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07139e9-e877-4d3a-974c-daaa9d77ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(400.390625, 800, 1024), np.log10(int_response[0]))\n",
    "plt.title(\"Example of primary beam response\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640ae5b-e042-4f80-a3a8-548b9016f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CORRECTING FOR PRIMARY BEAM RESPONSE ##\n",
    "\n",
    "p_corrected_sp = []\n",
    "\n",
    "for i, (spectra, presponse) in enumerate(zip(spectra_at_peak, presponse_norm)):\n",
    "    presponse_ds = int_response[::4]                             # Downsample primary response spectrum from 1024 freq channels to 256 (matching data)\n",
    "    spectra_at_peak_corrected = spectra_at_peak / presponse_ds   # Correction\n",
    "    p_corrected_sp.append(spectra_at_peak_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979d5f3-5c96-421a-8ae7-484f50f7e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SYNTHESIZED BEAM RESPONSE + CORRECTING\n",
    "\n",
    "sbm = formed.FFTFormedBeamModel()\n",
    "\n",
    "calibrated_spectra = []\n",
    "\n",
    "for i, (beam_id, ha, y, spectrum) in enumerate(zip(beam_ids, has_at_peak, y_at_peak, p_corrected_sp)):\n",
    "    sensitivity = sbm.get_sensitivity([beam_id], np.array([ha, y_at_peak]).T, freqs).squeeze()\n",
    "    \n",
    "    mean_sensitivity = np.nanmean(sensitivity, axis=1)            # Average sensitivity across frequencies\n",
    "    peak_sensitivity_ind = np.argmax(mean_sensitivity)            \n",
    "    sensitivity_at_peak = sensitivity[peak_sensitivity_ind, :]    # Spectrum of synthesized response at its peak\n",
    "\n",
    "    spectra_corrected = spectrum / sensitivity_at_peak            # Correction\n",
    "    spectra_jy = bf_to_jy(spectra_corrected, 1)                   # Conversion\n",
    "    calibrated_spectra.append(spectra_jy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
